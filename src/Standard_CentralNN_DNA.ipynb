{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import necessary libraries and modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%bash\n",
    "\n",
    "# kaggle datasets download -d nageshsingh/dna-sequence-dataset\n",
    "# mkdir data data/DNA\n",
    "# unzip dna-sequence-dataset.zip -d data/DNA\n",
    "# rm dna-sequence-dataset.zip\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 14\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m nn\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfunctional\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mF\u001b[39;00m\n\u001b[1;32m---> 14\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mflwr\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mfl\u001b[39;00m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mflwr\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcommon\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     16\u001b[0m     Metrics, EvaluateIns, EvaluateRes, FitIns, FitRes, MetricsAggregationFn, \n\u001b[0;32m     17\u001b[0m     Scalar, logger, ndarrays_to_parameters, parameters_to_ndarrays,\n\u001b[0;32m     18\u001b[0m     Parameters, NDArrays\n\u001b[0;32m     19\u001b[0m )\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mflwr\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mserver\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mclient_proxy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ClientProxy\n",
      "File \u001b[1;32mc:\\Users\\danoruo\\AppData\\Local\\miniconda3\\envs\\envt_py310\\lib\\site-packages\\flwr\\__init__.py:20\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;124;03m\"\"\"Flower main package.\"\"\"\u001b[39;00m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mflwr\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcommon\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mversion\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m package_version \u001b[38;5;28;01mas\u001b[39;00m _package_version\n\u001b[1;32m---> 20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m client, common, driver, server, simulation\n\u001b[0;32m     22\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m     23\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclient\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     24\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcommon\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     27\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msimulation\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     28\u001b[0m ]\n\u001b[0;32m     30\u001b[0m __version__ \u001b[38;5;241m=\u001b[39m _package_version\n",
      "File \u001b[1;32mc:\\Users\\danoruo\\AppData\\Local\\miniconda3\\envs\\envt_py310\\lib\\site-packages\\flwr\\simulation\\__init__.py:23\u001b[0m\n\u001b[0;32m     20\u001b[0m is_ray_installed \u001b[38;5;241m=\u001b[39m importlib\u001b[38;5;241m.\u001b[39mutil\u001b[38;5;241m.\u001b[39mfind_spec(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mray\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_ray_installed:\n\u001b[1;32m---> 23\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mflwr\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msimulation\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapp\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m start_simulation\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     25\u001b[0m     RAY_IMPORT_ERROR: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\"\"\u001b[39m\u001b[38;5;124mUnable to import module `ray`.\u001b[39m\n\u001b[0;32m     26\u001b[0m \n\u001b[0;32m     27\u001b[0m \u001b[38;5;124mTo install the necessary dependencies, install `flwr` with the `simulation` extra:\u001b[39m\n\u001b[0;32m     28\u001b[0m \n\u001b[0;32m     29\u001b[0m \u001b[38;5;124m    pip install -U flwr[\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msimulation\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m]\u001b[39m\n\u001b[0;32m     30\u001b[0m \u001b[38;5;124m\"\"\"\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\danoruo\\AppData\\Local\\miniconda3\\envs\\envt_py310\\lib\\site-packages\\flwr\\simulation\\app.py:23\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mlogging\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ERROR, INFO\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtyping\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Any, Callable, Dict, List, Optional, Type, Union\n\u001b[1;32m---> 23\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mray\u001b[39;00m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mray\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutil\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mscheduling_strategies\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m NodeAffinitySchedulingStrategy\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mflwr\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mclient\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ClientLike\n",
      "File \u001b[1;32mc:\\Users\\danoruo\\AppData\\Local\\miniconda3\\envs\\envt_py310\\lib\\site-packages\\ray\\__init__.py:76\u001b[0m\n\u001b[0;32m     71\u001b[0m         \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mctypes\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m CDLL\n\u001b[0;32m     73\u001b[0m         CDLL(so_path, ctypes\u001b[38;5;241m.\u001b[39mRTLD_GLOBAL)\n\u001b[1;32m---> 76\u001b[0m \u001b[43m_configure_system\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     77\u001b[0m \u001b[38;5;66;03m# Delete configuration function.\u001b[39;00m\n\u001b[0;32m     78\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m _configure_system\n",
      "File \u001b[1;32mc:\\Users\\danoruo\\AppData\\Local\\miniconda3\\envs\\envt_py310\\lib\\site-packages\\ray\\__init__.py:73\u001b[0m, in \u001b[0;36m_configure_system\u001b[1;34m()\u001b[0m\n\u001b[0;32m     70\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mctypes\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mctypes\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m CDLL\n\u001b[1;32m---> 73\u001b[0m \u001b[43mCDLL\u001b[49m\u001b[43m(\u001b[49m\u001b[43mso_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctypes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mRTLD_GLOBAL\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\danoruo\\AppData\\Local\\miniconda3\\envs\\envt_py310\\lib\\ctypes\\__init__.py:374\u001b[0m, in \u001b[0;36mCDLL.__init__\u001b[1;34m(self, name, mode, handle, use_errno, use_last_error, winmode)\u001b[0m\n\u001b[0;32m    371\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_FuncPtr \u001b[38;5;241m=\u001b[39m _FuncPtr\n\u001b[0;32m    373\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m handle \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 374\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_handle \u001b[38;5;241m=\u001b[39m \u001b[43m_dlopen\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    375\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    376\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_handle \u001b[38;5;241m=\u001b[39m handle\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pickle\n",
    "import time\n",
    "from collections import OrderedDict\n",
    "from typing import (\n",
    "    List, Tuple, Dict, Optional, Callable, Union\n",
    ")\n",
    "\n",
    "import numpy as np\n",
    "import torchvision\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import flwr as fl\n",
    "from flwr.common import (\n",
    "    Metrics, EvaluateIns, EvaluateRes, FitIns, FitRes, MetricsAggregationFn, \n",
    "    Scalar, logger, ndarrays_to_parameters, parameters_to_ndarrays,\n",
    "    Parameters, NDArrays\n",
    ")\n",
    "\n",
    "from flwr.server.client_proxy import ClientProxy\n",
    "from flwr.server.client_manager import ClientManager\n",
    "from flwr.server.strategy.aggregate import weighted_loss_avg, aggregate\n",
    "from logging import WARNING\n",
    "\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Architecture Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        num_classes: An integer indicating the number of classes in the dataset.\n",
    "    \"\"\"\n",
    "    def __init__(self, num_classes=10) -> None:\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_sp, 64)\n",
    "        self.fc2 = nn.Linear(64, 32)\n",
    "        self.fc3 = nn.Linear(32, 16)\n",
    "        self.fc4 = nn.Linear(16, 8)\n",
    "        self.fc5 = nn.Linear(8, num_classes)        \n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Forward pass of the neural network\n",
    "        \"\"\"\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = F.relu(self.fc4(x))        \n",
    "        x = self.fc5(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the FlowerClient class for federated learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FlowerClient(fl.client.NumPyClient):\n",
    "    def __init__(self, cid, net, trainloader, valloader, device, batch_size, save_results, matrix_path, roc_path,\n",
    "                 yaml_path, classes):\n",
    "        self.net = net\n",
    "        self.trainloader = trainloader\n",
    "        self.valloader = valloader\n",
    "        self.cid = cid\n",
    "        self.device = device\n",
    "        self.batch_size = batch_size\n",
    "        self.save_results = save_results\n",
    "        self.matrix_path = matrix_path\n",
    "        self.roc_path = roc_path\n",
    "        self.yaml_path = yaml_path\n",
    "        self.classes = classes\n",
    "\n",
    "    def get_parameters(self, config):\n",
    "        print(f\"[Client {self.cid}] get_parameters\")\n",
    "        return get_parameters2(self.net)\n",
    "\n",
    "    def fit(self, parameters, config):\n",
    "        server_round = config['server_round']\n",
    "        local_epochs = config['local_epochs']\n",
    "        lr = float(config[\"learning_rate\"])\n",
    "\n",
    "        print(f'[Client {self.cid}, round {server_round}] fit, config: {config}')\n",
    "\n",
    "        set_parameters(self.net, parameters)\n",
    "\n",
    "        criterion = torch.nn.CrossEntropyLoss()\n",
    "        optimizer = torch.optim.Adam(self.net.parameters(), lr=lr)\n",
    "\n",
    "        results = engine.train(self.net, self.trainloader, self.valloader, optimizer=optimizer, loss_fn=criterion,\n",
    "                               epochs=local_epochs, device=self.device)\n",
    "\n",
    "        if self.save_results:\n",
    "            save_graphs(self.save_results, local_epochs, results, f\"_Client {self.cid}\")\n",
    "\n",
    "        return get_parameters2(self.net), len(self.trainloader), {}\n",
    "\n",
    "    def evaluate(self, parameters, config):\n",
    "        print(f\"[Client {self.cid}] evaluate, config: {config}\")\n",
    "        set_parameters(self.net, parameters)\n",
    "\n",
    "        loss, accuracy, y_pred, y_true, y_proba = engine.test(self.net, self.valloader,\n",
    "                                                              loss_fn=torch.nn.CrossEntropyLoss(), device=self.device)\n",
    "\n",
    "        if self.save_results:\n",
    "            os.makedirs(self.save_results, exist_ok=True)\n",
    "            if self.matrix_path:\n",
    "                save_matrix(y_true, y_pred, self.save_results + self.matrix_path, self.classes)\n",
    "            if self.roc_path:\n",
    "                save_roc(y_true, y_proba, self.save_results + self.roc_path, len(self.classes))\n",
    "\n",
    "        return float(loss), len(self.valloader), {\"accuracy\": float(accuracy)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the client_common function to set up the Flower client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def client_common(cid, model_save, path_yaml, path_roc, results_save, path_matrix,\n",
    "                  batch_size, trainloaders, valloaders, DEVICE, CLASSES):\n",
    "    trainloader = trainloaders[int(cid)]\n",
    "    valloader = valloaders[int(cid)]\n",
    "\n",
    "    net = Net(num_classes=len(CLASSES)).to(DEVICE)\n",
    "\n",
    "    if os.path.exists(model_save):\n",
    "        print(\" To get the checkpoint\")\n",
    "        checkpoint = torch.load(model_save, map_location=DEVICE)['model_state_dict']\n",
    "        net.load_state_dict(checkpoint)\n",
    "\n",
    "    return FlowerClient(cid, net, trainloader, valloader, device=DEVICE, batch_size=batch_size,\n",
    "                        matrix_path=path_matrix, roc_path=path_roc, save_results=results_save, yaml_path=path_yaml,\n",
    "                        classes=CLASSES)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define utility functions for federated learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weighted_average(metrics: List[Tuple[int, Metrics]]) -> Metrics:\n",
    "    accuracies = [num_examples * m[\"accuracy\"] for num_examples, m in metrics]\n",
    "    examples = [num_examples for num_examples, _ in metrics]\n",
    "    return {\"accuracy\": sum(accuracies) / sum(examples)}\n",
    "\n",
    "def evaluate2(server_round: int, parameters: NDArrays,\n",
    "              config: Dict[str, Scalar]) -> Optional[Tuple[float, Dict[str, Scalar]]]:\n",
    "    set_parameters(central, parameters)\n",
    "    loss, accuracy, y_pred, y_true, y_proba = engine.test(central, testloader, loss_fn=torch.nn.CrossEntropyLoss(),\n",
    "                                                          device=DEVICE)\n",
    "    os.makedirs(save_results, exist_ok=True)\n",
    "    save_matrix(y_true, y_pred, save_results + \"confusion_matrix_test.png\", CLASSES)\n",
    "    save_roc(y_true, y_proba, save_results + \"roc_test.png\", len(CLASSES))\n",
    "    \n",
    "    print(f\"Server-side evaluation loss {loss} / accuracy {accuracy}\")\n",
    "    return loss, {\"accuracy\": accuracy}\n",
    "\n",
    "def get_on_fit_config_fn(epoch=2, lr=0.001, batch_size=32) -> Callable[[int], Dict[str, str]]: #Originally 32\n",
    "    def fit_config(server_round: int) -> Dict[str, str]:\n",
    "        config = {\n",
    "            \"learning_rate\": str(lr),\n",
    "            \"batch_size\": str(batch_size),\n",
    "            \"server_round\": server_round,\n",
    "            \"local_epochs\": epoch\n",
    "        }\n",
    "        return config\n",
    "    return fit_config\n",
    "\n",
    "def aggreg_fit_checkpoint(server_round, aggregated_parameters, central_model, path_checkpoint):\n",
    "    if aggregated_parameters is not None:\n",
    "        print(f\"Saving round {server_round} aggregated_parameters...\")\n",
    "        aggregated_ndarrays: List[np.ndarray] = parameters_to_ndarrays(aggregated_parameters)\n",
    "        \n",
    "        params_dict = zip(central_model.state_dict().keys(), aggregated_ndarrays)\n",
    "        state_dict = OrderedDict({k: torch.tensor(v) for k, v in params_dict})\n",
    "        central_model.load_state_dict(state_dict, strict=True)\n",
    "        if path_checkpoint:\n",
    "            torch.save({\n",
    "                'model_state_dict': central_model.state_dict(),\n",
    "            }, path_checkpoint)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the FedCustom strategy class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A Strategy from scratch with the same sampling of the clients as it is in FedAvg\n",
    "# and then change the configuration dictionary\n",
    "class FedCustom(fl.server.strategy.Strategy):\n",
    "    def __init__(\n",
    "            self,\n",
    "            fraction_fit: float = 1.0,\n",
    "            fraction_evaluate: float = 1.0,\n",
    "            min_fit_clients: int = 2,\n",
    "            min_evaluate_clients: int = 2,\n",
    "            min_available_clients: int = 2,\n",
    "            evaluate_fn: Optional[\n",
    "                    Callable[[int, NDArrays, Dict[str, Scalar]], Optional[Tuple[float, Dict[str, Scalar]]]]\n",
    "                ] = None,\n",
    "            on_fit_config_fn: Optional[Callable[[int], Dict[str, Scalar]]] = None,\n",
    "            on_evaluate_config_fn: Optional[Callable[[int], Dict[str, Scalar]]] = None,\n",
    "            accept_failures: bool = True,\n",
    "            initial_parameters: Optional[Parameters] = None,\n",
    "            fit_metrics_aggregation_fn: Optional[MetricsAggregationFn] = None,\n",
    "            evaluate_metrics_aggregation_fn: Optional[MetricsAggregationFn] = None,\n",
    "    ) -> None:\n",
    "        super().__init__()\n",
    "        self.fraction_fit = fraction_fit\n",
    "        self.fraction_evaluate = fraction_evaluate\n",
    "        self.min_fit_clients = min_fit_clients\n",
    "        self.min_evaluate_clients = min_evaluate_clients\n",
    "        self.min_available_clients = min_available_clients\n",
    "        self.evaluate_fn = evaluate_fn\n",
    "        self.on_fit_config_fn = on_fit_config_fn\n",
    "        self.on_evaluate_config_fn = on_evaluate_config_fn,\n",
    "        self.accept_failures = accept_failures\n",
    "        self.initial_parameters = initial_parameters\n",
    "        self.fit_metrics_aggregation_fn = fit_metrics_aggregation_fn\n",
    "        self.evaluate_metrics_aggregation_fn = evaluate_metrics_aggregation_fn\n",
    "\n",
    "    def __repr__(self) -> str:\n",
    "        # Same function as FedAvg(Strategy)\n",
    "        return f\"FedCustom (accept_failures={self.accept_failures})\"\n",
    "\n",
    "    def initialize_parameters(\n",
    "        self, client_manager: ClientManager\n",
    "    ) -> Optional[Parameters]:\n",
    "        \"\"\"Initialize global model parameters.\"\"\"\n",
    "        # Same function as FedAvg(Strategy)\n",
    "        initial_parameters = self.initial_parameters\n",
    "        self.initial_parameters = None  # Don't keep initial parameters in memory\n",
    "        return initial_parameters\n",
    "\n",
    "    def num_fit_clients(self, num_available_clients: int) -> Tuple[int, int]:\n",
    "        \"\"\"Return sample size and required number of clients.\"\"\"\n",
    "        # Same function as FedAvg(Strategy)\n",
    "        num_clients = int(num_available_clients * self.fraction_fit)\n",
    "        return max(num_clients, self.min_fit_clients), self.min_available_clients\n",
    "\n",
    "    def configure_fit(\n",
    "        self, server_round: int, parameters: Parameters, client_manager: ClientManager\n",
    "    ) -> List[Tuple[ClientProxy, FitIns]]:\n",
    "        \"\"\"Configure the next round of training.\"\"\"\n",
    "        # Sample clients\n",
    "        sample_size, min_num_clients = self.num_fit_clients(\n",
    "            client_manager.num_available()\n",
    "        )\n",
    "\n",
    "        clients = client_manager.sample(\n",
    "            num_clients=sample_size, min_num_clients=min_num_clients\n",
    "        )\n",
    "        # Create custom configs\n",
    "        n_clients = len(clients)\n",
    "        half_clients = n_clients // 2\n",
    "        # Custom fit config function provided\n",
    "        standard_lr = lr\n",
    "        higher_lr = 0.003\n",
    "        config = {\"server_round\": server_round, \"local_epochs\": 1}\n",
    "        if self.on_fit_config_fn is not None:\n",
    "            # Custom fit config function provided\n",
    "            config = self.on_fit_config_fn(server_round)\n",
    "\n",
    "        # fit_ins = FitIns(parameters, config)\n",
    "        # Return client/config pairs\n",
    "        fit_configurations = []\n",
    "        for idx, client in enumerate(clients):\n",
    "            config[\"learning_rate\"] = standard_lr if idx < half_clients else higher_lr\n",
    "            \"\"\"\n",
    "            Each pair of (ClientProxy, FitRes) constitutes \n",
    "            a successful update from one of the previously selected clients.\n",
    "            \"\"\"\n",
    "            fit_configurations.append(\n",
    "                (\n",
    "                    client,\n",
    "                    FitIns(\n",
    "                        parameters,\n",
    "                        config\n",
    "                    )\n",
    "                )\n",
    "            )\n",
    "        # Successful updates from the previously selected and configured clients\n",
    "        return fit_configurations\n",
    "\n",
    "    def aggregate_fit(\n",
    "        self,\n",
    "        server_round: int,\n",
    "        results: List[Tuple[ClientProxy, FitRes]],\n",
    "        failures: List[Union[Tuple[ClientProxy, FitRes], BaseException]],\n",
    "    ) -> Tuple[Optional[Parameters], Dict[str, Scalar]]:\n",
    "        \"\"\"Aggregate fit results using weighted average. (each round)\"\"\"\n",
    "        # Same function as FedAvg(Strategy)\n",
    "        if not results:\n",
    "            return None, {}\n",
    "\n",
    "        # Do not aggregate if there are failures and failures are not accepted\n",
    "        if not self.accept_failures and failures:\n",
    "            return None, {}\n",
    "\n",
    "        # Convert results parameters --> array matrix\n",
    "        weights_results = [\n",
    "            (parameters_to_ndarrays(fit_res.parameters), fit_res.num_examples)\n",
    "            for _, fit_res in results\n",
    "        ]\n",
    "\n",
    "        # Aggregate parameters using weighted average between the clients and convert back to parameters object (bytes)\n",
    "        parameters_aggregated = ndarrays_to_parameters(aggregate(weights_results))\n",
    "\n",
    "        metrics_aggregated = {}\n",
    "        # Aggregate custom metrics if aggregation fn was provided\n",
    "        if self.fit_metrics_aggregation_fn:\n",
    "            fit_metrics = [(res.num_examples, res.metrics) for _, res in results]\n",
    "            metrics_aggregated = self.fit_metrics_aggregation_fn(fit_metrics)\n",
    "\n",
    "        elif server_round == 1:  # Only log this warning once\n",
    "            logger.log(WARNING, \"No fit_metrics_aggregation_fn provided\")\n",
    "\n",
    "        # Same function as SaveModelStrategy(fl.server.strategy.FedAvg)\n",
    "        \"\"\"Aggregate model weights using weighted average and store checkpoint\"\"\"\n",
    "        aggreg_fit_checkpoint(server_round, parameters_aggregated, central, model_save)\n",
    "        return parameters_aggregated, metrics_aggregated\n",
    "\n",
    "    def num_evaluation_clients(self, num_available_clients: int) -> Tuple[int, int]:\n",
    "        \"\"\"Use a fraction of available clients for evaluation.\"\"\"\n",
    "        # Same function as FedAvg(Strategy)\n",
    "        num_clients = int(num_available_clients * self.fraction_evaluate)\n",
    "        return max(num_clients, self.min_evaluate_clients), self.min_available_clients\n",
    "\n",
    "    def configure_evaluate(\n",
    "        self, server_round: int, parameters: Parameters, client_manager: ClientManager\n",
    "    ) -> List[Tuple[ClientProxy, EvaluateIns]]:\n",
    "        \"\"\"Configure the next round of evaluation.\"\"\"\n",
    "        # Same function as FedAvg(Strategy)\n",
    "        # Do not configure federated evaluation if fraction eval is 0.\n",
    "        if self.fraction_evaluate == 0.0:\n",
    "            return []\n",
    "\n",
    "        # Parameters and config\n",
    "        config = {}  # {\"server_round\": server_round, \"local_epochs\": 1}\n",
    "\n",
    "        evaluate_ins = EvaluateIns(parameters, config)\n",
    "\n",
    "        # Sample clients\n",
    "        sample_size, min_num_clients = self.num_evaluation_clients(\n",
    "            client_manager.num_available()\n",
    "        )\n",
    "\n",
    "        clients = client_manager.sample(\n",
    "            num_clients=sample_size, min_num_clients=min_num_clients\n",
    "        )\n",
    "\n",
    "        # Return client/config pairs\n",
    "        # Each pair of (ClientProxy, FitRes) constitutes a successful update from one of the previously selected clients\n",
    "        return [(client, evaluate_ins) for client in clients]\n",
    "\n",
    "    def aggregate_evaluate(\n",
    "        self,\n",
    "        server_round: int,\n",
    "        results: List[Tuple[ClientProxy, EvaluateRes]],\n",
    "        failures: List[Union[Tuple[ClientProxy, EvaluateRes], BaseException]],\n",
    "    ) -> Tuple[Optional[float], Dict[str, Scalar]]:\n",
    "        \"\"\"Aggregate evaluation losses using weighted average.\"\"\"\n",
    "        # Same function as FedAvg(Strategy)\n",
    "        if not results:\n",
    "            return None, {}\n",
    "\n",
    "        # Do not aggregate if there are failures and failures are not accepted\n",
    "        if not self.accept_failures and failures:\n",
    "            return None, {}\n",
    "\n",
    "        # Aggregate loss\n",
    "        loss_aggregated = weighted_loss_avg(\n",
    "            [\n",
    "                (evaluate_res.num_examples, evaluate_res.loss)\n",
    "                for _, evaluate_res in results\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        metrics_aggregated = {}\n",
    "        # Aggregate custom metrics if aggregation fn was provided\n",
    "        if self.evaluate_metrics_aggregation_fn:\n",
    "            eval_metrics = [(res.num_examples, res.metrics) for _, res in results]\n",
    "            metrics_aggregated = self.evaluate_metrics_aggregation_fn(eval_metrics)\n",
    "\n",
    "        # Only log this warning once\n",
    "        elif server_round == 1:\n",
    "            logger.log(WARNING, \"No evaluate_metrics_aggregation_fn provided\")\n",
    "\n",
    "        return loss_aggregated, metrics_aggregated\n",
    "\n",
    "    def evaluate(\n",
    "        self, server_round: int, parameters: Parameters\n",
    "    ) -> Optional[Tuple[float, Dict[str, Scalar]]]:\n",
    "        \"\"\"Evaluate global model parameters using an evaluation function.\"\"\"\n",
    "        # Same function as FedAvg(Strategy)\n",
    "        if self.evaluate_fn is None:\n",
    "            # Let's assume we won't perform the global model evaluation on the server side.\n",
    "            return None\n",
    "\n",
    "        # if we have a global model evaluation on the server side :\n",
    "        parameters_ndarrays = parameters_to_ndarrays(parameters)\n",
    "        eval_res = self.evaluate_fn(server_round, parameters_ndarrays, {})\n",
    "\n",
    "        # if you haven't results\n",
    "        if eval_res is None:\n",
    "            return None\n",
    "\n",
    "        loss, metrics = eval_res\n",
    "        return loss, metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up the federated learning strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up your variables directly\n",
    "data_path = 'data/'\n",
    "dataset = 'DNA'\n",
    "yaml_path = './results/CL_DNA/results.yml'\n",
    "seed = 0\n",
    "num_workers = 0\n",
    "max_epochs = 25\n",
    "batch_size = 16\n",
    "splitter = 10\n",
    "device = 'gpu'\n",
    "number_clients = 1 # Originally 1\n",
    "save_results = 'results/CL_DNA/'\n",
    "matrix_path = 'confusion_matrix.png'\n",
    "roc_path = 'roc.png'\n",
    "model_save = 'results/CL_DNA/DNA_cl.pt'\n",
    "min_fit_clients = 1\n",
    "min_avail_clients = 1\n",
    "min_eval_clients = 1\n",
    "rounds = 1\n",
    "frac_fit = 1.0\n",
    "frac_eval = 1.0\n",
    "lr = 1e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DNA\n",
      "The training set is created for the classes: ('0', '1', '2', '3', '4', '5', '6')\n"
     ]
    }
   ],
   "source": [
    "DEVICE = torch.device(choice_device(device))\n",
    "CLASSES = classes_string(dataset)\n",
    "trainloaders, valloaders, testloader = data_setup.load_datasets(num_clients=number_clients, batch_size=batch_size, resize=None, seed=seed, num_workers=num_workers, splitter=splitter, dataset=dataset, data_path=data_path, data_path_val=None)\n",
    "_, input_sp = next(iter(testloader))[0].shape\n",
    "central = Net(num_classes=len(CLASSES)).to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "strategy = FedCustom(\n",
    "    fraction_fit=frac_fit,\n",
    "    fraction_evaluate=frac_eval,\n",
    "    min_fit_clients=min_fit_clients,\n",
    "    min_evaluate_clients=min_eval_clients if min_eval_clients else number_clients // 2,\n",
    "    min_available_clients=min_avail_clients,\n",
    "    evaluate_metrics_aggregation_fn=weighted_average,\n",
    "    initial_parameters=ndarrays_to_parameters(get_parameters2(central)),\n",
    "    evaluate_fn=evaluate2,\n",
    "    on_fit_config_fn=get_on_fit_config_fn(epoch=max_epochs, batch_size=batch_size),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DNA\n",
      "The training set is created for the classes: ('0', '1', '2', '3', '4', '5', '6')\n"
     ]
    }
   ],
   "source": [
    "trainloaders, valloaders, testloader = data_setup.load_datasets(num_clients=number_clients,\n",
    "                                                                batch_size=batch_size,\n",
    "                                                                resize=None,\n",
    "                                                                seed=seed,\n",
    "                                                                num_workers=num_workers,\n",
    "                                                                splitter=splitter,\n",
    "                                                                dataset=dataset,  # Use the specified dataset\n",
    "                                                                data_path=data_path,\n",
    "                                                                data_path_val=None)  # Use the same path for validation data\n",
    "\n",
    "def client_fn(cid: str) -> FlowerClient:\n",
    "    return client_common(cid,\n",
    "                         model_save, path_yaml, path_roc, results_save, path_matrix,\n",
    "                         batch_size, trainloaders, valloaders, DEVICE, CLASSES)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the client_fn function and set up the simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO flwr 2025-06-05 11:27:51,583 | app.py:175 | Starting Flower simulation, config: ServerConfig(num_rounds=1, round_timeout=None)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "flwr 1.5.0\n",
      "numpy 1.26.4\n",
      "torch 2.3.1+cpu\n",
      "torchvision 0.18.1+cpu\n",
      "Training on cpu\n",
      "Start simulation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-05 11:27:57,811\tERROR services.py:1362 -- Failed to start the dashboard , return code 3221226505\n",
      "2025-06-05 11:27:57,812\tERROR services.py:1387 -- Error should be written to 'dashboard.log' or 'dashboard.err'. We are printing the last 20 lines for you. See 'https://docs.ray.io/en/master/ray-observability/user-guides/configure-logging.html#logging-directory-structure' to find where the log file is.\n",
      "2025-06-05 11:27:57,812\tERROR services.py:1431 -- \n",
      "The last 20 lines of C:\\Users\\danoruo\\AppData\\Local\\Temp\\ray\\session_2025-06-05_11-27-52_528834_1780\\logs\\dashboard.log (it contains the error message from the dashboard): \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\danoruo\\AppData\\Local\\miniconda3\\envs\\envt_py310\\lib\\site-packages\\ray\\dashboard\\dashboard.py\", line 247, in <module>\n",
      "    logging_utils.redirect_stdout_stderr_if_needed(\n",
      "  File \"c:\\Users\\danoruo\\AppData\\Local\\miniconda3\\envs\\envt_py310\\lib\\site-packages\\ray\\_private\\logging_utils.py\", line 48, in redirect_stdout_stderr_if_needed\n",
      "    sys.stderr = open_log(stderr_fileno, unbuffered=True, closefd=False)\n",
      "  File \"c:\\Users\\danoruo\\AppData\\Local\\miniconda3\\envs\\envt_py310\\lib\\site-packages\\ray\\_private\\utils.py\", line 446, in open_log\n",
      "    stream = open(path, **kwargs)\n",
      "OSError: [WinError 6] The handle is invalid\n",
      "\n",
      "\n",
      "2025-06-05 11:27:58,678\tINFO worker.py:1888 -- Started a local Ray instance.\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")\n",
    "\n",
    "print(\"flwr\", fl.__version__)\n",
    "print(\"numpy\", np.__version__)\n",
    "print(\"torch\", torch.__version__)\n",
    "print(\"torchvision\", torchvision.__version__)\n",
    "print(f\"Training on {DEVICE}\")\n",
    "\n",
    "client_resources = {\"num_cpus\": 1}\n",
    "\n",
    "if DEVICE.type == \"cuda\":\n",
    "    client_resources[\"num_gpus\"] = 1\n",
    "\n",
    "model_save = model_save\n",
    "path_yaml = yaml_path\n",
    "path_roc = roc_path\n",
    "results_save = save_results\n",
    "path_matrix = matrix_path\n",
    "batch_size = batch_size\n",
    "\n",
    "print(\"Start simulation\")\n",
    "start_simulation = time.time()\n",
    "fl.simulation.start_simulation(\n",
    "    client_fn=client_fn,\n",
    "    num_clients=number_clients,\n",
    "    config=fl.server.ServerConfig(num_rounds=rounds),\n",
    "    strategy=strategy,\n",
    "    client_resources=client_resources\n",
    ")\n",
    "print(f\"Simulation Time = {time.time() - start_simulation} seconds\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "envt_py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
